{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bccadcbb-daae-443a-bde8-b30910d7a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edited: 2025: Sabrina\n",
    "#Edited 2020: Johannes\n",
    "# This is an example script for the use of the PointConcentration class/object for pointconcentration measurements\n",
    "#from the windtunnel python package, showing the use of almost all available analysis functions.\n",
    "\n",
    "# The columns in the input file are expected to be time, wtref, slow FID, fast ID, release signal and open_rate, \n",
    "# where release signal will be ignored.\n",
    "# The PointConcentration class returns a DataFrame, using the standard measurement txt-file output as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fa7d992-a0c9-4fb5-b307-2da59663cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3747b78d-91ef-40de-9a9d-9ac54cb094b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path and file names\n",
    "\n",
    "# Add the parent directory to the path for the windtunnel package import\n",
    "path_dir = \"/home/sabrina/Desktop/Schreibtisch/Arbeit_2025/WTSoftwareUtilitiesShare\"\n",
    "sys.path.append(os.path.abspath(path_dir))\n",
    "import windtunnel as wt\n",
    "\n",
    "#Path to your input data\n",
    "path = f\"{path_dir}/ExampleData/InputData/Zeitserie1/\"\n",
    "# Name of your measurement files prefix\n",
    "namelist = ['BFS_BD3_MP01_000']\n",
    "\n",
    "#Path to your output folder for average files and plots\n",
    "output_path = f\"{path_dir}/ExampleData/Results/\"\n",
    "\n",
    "#For PointData for the functions to work the columns of the file should be: time, wtref, slow_FID, fast_FID, open_rate\n",
    "#(See manual for the description of the variables)\n",
    "\n",
    "#Name of csv file which contains ambient conditions data. Multiple diff. ambient conditions for diff datasets can be read-in at ones\n",
    "#If no file given or configuration wrong, the program ressorts to try reading-in given values manually below. \n",
    "#csv_file='ambient_conditions.csv'\n",
    "csv_file= f\"{path_dir}/ExampleData/ParameterFiles/ambient_conditions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abcd3ccd-79a7-4aec-9389-992312536a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables and Parameters set for all ts, if no ambient_conditions.csv file overgiven\n",
    "\n",
    "#If at the end calculate entdimensionalised or full scale transform quantities\n",
    "#Default: nd:entdimensionalise, ms:model scale, fs:full scale.    \n",
    "full_scale='ms'\n",
    "\n",
    "#Postprocessing before analysis\n",
    "applyPostprocessing=True\n",
    "averageInterval=60 #s  #Interval to downaverage raw time series to before analysis\n",
    "\n",
    "#Overgive uncertainty\n",
    "uncertainty_value=None #Uncertainty of concentration, has to be calculated/estimated from the experimentator\n",
    "#If None overgive no error visualized as errorbars 0.5\n",
    "uncertainty_representation=\"percentage\" #\"absoluteValue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f04befb-09d2-45a8-a3de-6b6211926b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example file/Default environment values if no csv_file found:\n",
    "\n",
    "#Source location  [mm]\n",
    "x_source=0\n",
    "y_source=0\n",
    "z_source=0\n",
    "\n",
    "#Source mass flow controller, calibration settings\n",
    "mass_flow_controller=0.300 #[l/h]*1/100 #'X'  #Controller(settings) used, just a name placeholder for orientation, not used yet\n",
    "#If calibration performed on a controller, corrects actual max. flow capacity of controller\n",
    "calibration_curve=0.3     #0.3 oder 3\n",
    "calibration_factor=0 #1      #\n",
    "\n",
    "#Gas characteristics\n",
    "gas_name='C12'           #Just placeholder name variable for orientation, not used for anything\n",
    "gas_factor=0.5   #[-]    #!!! Needs to be calculate/specificate f.e. if gas changes \n",
    "mol_weight=29.0 #28.97 #Air [g/mol]\n",
    "\n",
    "\n",
    "#Measurement location [mm]\n",
    "x_measure=1020 #855.16\n",
    "y_measure= 0    #176.29\n",
    "z_measure= 5     #162\n",
    "\n",
    "#Surrounding conditions\n",
    "pressure=101426.04472        #1009.38  #[hPa] ->Pa\n",
    "temperature=23             #23.5  #[°C]\n",
    "\n",
    "#Model to Reality scaling\n",
    "scale=400                     #250      #Model/Reality\n",
    "scaling_factor=0.5614882               #0.637       #USA1 to selected ref pos.?\n",
    "ref_length=1/400              #1/250           #Lref\n",
    "ref_height=100/400            #None            #Href\n",
    "\n",
    "\n",
    "full_scale_wtref=10             #6         #Uref_fullscale\n",
    "full_scale_flow_rate=0.002     #Q_amb[kg/s]?   #0.5   #Qv_fullscale\n",
    "full_scale_temp=20             #[°C]\n",
    "full_scale_pressure=101325     #[Pa]\n",
    "#Q_ambient[kg/s] ->  Q[m³/s]=Q[kg/s]*R*T/(M*p)\n",
    "\n",
    "#Variable wdir for wind direction. To be implemented in future. ##\n",
    "#wdir=0\n",
    "#Variable axis_range. Reserved for future implementation of axis range specification, \n",
    "#analogously to puff mode\n",
    "#axis_range='auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15fd4245-1f85-47d7-a207-ba9d6f9d1d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BFS_BD3_MP01_000': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Initialise concentration ts dictionary of length namelist, as well as for full scale and entdimensionalised\n",
    "conc_ts = {}\n",
    "conc_ts.fromkeys(namelist)\n",
    "conc_ts_fs = conc_ts\n",
    "conc_ts_nd = conc_ts\n",
    "\n",
    "dict_conc_ts = conc_ts\n",
    "dict_conc_nd = conc_ts\n",
    "dict_conc_fs = conc_ts\n",
    "\n",
    "data_dict = {}\n",
    "data_dict.fromkeys(namelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76c2b516-3205-4773-aab7-67d379acbd06",
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Testing nothing should be read-in already\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(conc_ts[\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconc_ts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m][\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(conc_ts[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(conc_ts))]))]\u001b[38;5;241m.\u001b[39mx_source)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(conc_ts[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(conc_ts))][\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(conc_ts[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(conc_ts))]))]\u001b[38;5;241m.\u001b[39mtemperature)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(conc_ts[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(conc_ts))][\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(conc_ts[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(conc_ts))]))]\u001b[38;5;241m.\u001b[39mmass_flow_controller)\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Testing nothing should be read-in already\n",
    "print(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].x_source)\n",
    "print(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].temperature)\n",
    "print(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].mass_flow_controller)\n",
    "print(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].scaling_factor)\n",
    "print(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].gas_factor)\n",
    "print(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].full_scale_flow_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad98c924-46f3-4122-97a8-2dc2a6853753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in ambient conditions for each folder or concentration ts from given csv file or for same conditions from manually\n",
    "parameters_PerFolder = False  #True=for each folder/namelist entry new column, False: for each ts one column entry\n",
    "\n",
    "for name in namelist:\n",
    "    if parameters_PerFolder==True:\n",
    "        #Read ambient conditions from csv file only for each folder\n",
    "        ambient_conditions = wt.PointConcentration.get_ambient_conditions(path=path, name=name, input_file=csv_file)\n",
    "        #Else read/use given default from cell above\n",
    "        if ambient_conditions is None:\n",
    "            []\n",
    "        #Read ambient conditions from csv file\n",
    "        else:\n",
    "            x_source, y_source, z_source, x_measure, y_measure, z_measure, pressure, temperature, calibration_curve, mass_flow_controller, calibration_factor, scaling_factor, scale, ref_length, \\\n",
    "            ref_height, gas_name, mol_weight, gas_factor, full_scale_wtref, full_scale_flow_rate, full_scale_temp, full_scale_pressure = wt.PointConcentration.read_ambient_conditions(\n",
    "                ambient_conditions, name)\n",
    "        \n",
    "    files = wt.get_files(path, name)\n",
    "    print(files)\n",
    "\n",
    "    #Initilise Dictionary for each given name containing dimensions of nr of files ts#0-\n",
    "    conc_ts[name] = {}\n",
    "    conc_ts[name].fromkeys(files)\n",
    "    for file in files:\n",
    "        if parameters_PerFolder == False:\n",
    "            #Read in ambient condition column for each ts\n",
    "            ambient_conditions = wt.PointConcentration.get_ambient_conditions(path=path, name=file, input_file=csv_file)\n",
    "            #Else read/use given default from cell above\n",
    "            if ambient_conditions is None:\n",
    "                []\n",
    "            #Read ambient conditions from csv file\n",
    "            else:\n",
    "                x_source, y_source, z_source, x_measure, y_measure, z_measure, pressure, temperature, calibration_curve, mass_flow_controller, calibration_factor, scaling_factor, scale, ref_length, \\\n",
    "                ref_height, gas_name, mol_weight, gas_factor, full_scale_wtref, full_scale_flow_rate, full_scale_temp, full_scale_pressure = wt.PointConcentration.read_ambient_conditions(\n",
    "                ambient_conditions, file)\n",
    "        \n",
    "        conc_ts[name][file] = wt.PointConcentration.from_file(path + file)\n",
    "    \n",
    "        conc_ts[name][file].ambient_conditions(x_source=x_source, y_source=y_source, z_source=z_source,\n",
    "                                               x_measure=x_measure, y_measure=y_measure, z_measure=z_measure,\n",
    "                                               pressure=pressure,\n",
    "                                               temperature=temperature,\n",
    "                                               calibration_curve=calibration_curve,\n",
    "                                               mass_flow_controller=mass_flow_controller,\n",
    "                                               calibration_factor=calibration_factor)\n",
    "\n",
    "#wdir,0,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf67842-b5ed-4d81-b8ba-2504560cf6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set read-in scaling, gas and full scale information to internal class variables\n",
    "for name in namelist:\n",
    "    for file in files:\n",
    "\n",
    "        conc_ts[name][file].scaling_information(scaling_factor=scaling_factor, \n",
    "                                                scale=scale,\n",
    "                                                ref_length=ref_length, \n",
    "                                                ref_height=ref_height)\n",
    "        \n",
    "        conc_ts[name][file].tracer_information(gas_name=gas_name,\n",
    "                                               mol_weight=mol_weight,\n",
    "                                               gas_factor=gas_factor)\n",
    "        \n",
    "        conc_ts[name][file].full_scale_information(full_scale_wtref=full_scale_wtref,\n",
    "                                                   full_scale_flow_rate=full_scale_flow_rate,\n",
    "                                                   full_scale_temp=full_scale_temp,full_scale_pressure=full_scale_pressure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741d4519-8006-49b0-b1d3-067b5fd68ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing everything from ambient-conditions file now read-in\n",
    "print(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].x_source)\n",
    "print(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].temperature)\n",
    "print(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].mass_flow_controller)\n",
    "print(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].scaling_factor)\n",
    "print(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].gas_factor)\n",
    "print(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].full_scale_flow_rate)\n",
    "#self = conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aa7cf0-8991-4062-8bac-645c272757e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculate mass flow rate, net concentration and dimensionalise concentration\n",
    "for name in namelist:\n",
    "    for file in files:\n",
    "        \n",
    "        conc_ts[name][file].convert_temperature()\n",
    "        conc_ts[name][file].calc_wtref_mean()\n",
    "        \n",
    "        conc_ts[name][file].calc_model_mass_flow_rate(usingMaxFlowRate=\"True\",applyCalibration=\"False\")\n",
    "        conc_ts[name][file].calc_net_concentration()\n",
    "\n",
    "        #conc_ts[name][file].clear_zeros()  #Remove values net_concentration =< 0 from dataset !noise\n",
    "        conc_ts[name][file].calc_c_star()\n",
    "\n",
    "        conc_ts[name][file].calc_full_scale_concentration() #Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c07167-344d-4174-a185-f33223686501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test c*star output\n",
    "print(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].c_star)\n",
    "#Test full scale trafo\n",
    "print(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].net_concentration)\n",
    "print(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].full_scale_concentration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a9f5a5-43bc-4542-8980-f18970d1121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].net_concentration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8863dbbd-3392-443b-b576-e9444af1c51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Options for Outputting data in full-scale, model scale, and non-dimensionally.\n",
    "\n",
    "for name in namelist:\n",
    "    for file in files:\n",
    "        \n",
    "        if full_scale == 'ms':\n",
    "            dict_conc_ts = conc_ts\n",
    "            \n",
    "        elif full_scale == 'fs':\n",
    "            dict_conc_ts = conc_ts_fs\n",
    "            dict_conc_ts[name][file].to_full_scale()\n",
    "            \n",
    "        elif full_scale == 'nd':\n",
    "            dict_conc_ts = conc_ts_nd\n",
    "            dict_conc_ts[name][file].to_non_dimensional()\n",
    "        else:\n",
    "            print(\n",
    "                \"Error: invalid input for full_scale. Data can only be computed in model scale (full_scale='ms'), full scale (full_scale='fs'), or non-dimensionally (full_scale=nd).\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0825fa7-f068-4ad3-87f8-50add21eeb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Postprocessing if overgiven\n",
    "measurementFreq=0.005 #Time series frequency #For now only for static case implemented\n",
    "averageInterval=averageInterval #60 #s\n",
    "columns=[\"net_concentration\"] #Columns to average down\n",
    "\n",
    "print(len(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))]))\n",
    "#print(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].net_concentration)\n",
    "if(applyPostprocessing==True):\n",
    "    for name in namelist:\n",
    "        for file in files:\n",
    "            dict_conc_ts[name][file].downAverage(averageInterval=averageInterval,measurementFreq=measurementFreq, columns=columns)\n",
    "            #dict_conc_ts[name][file].net_concentration\n",
    "\n",
    "print(len(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].net_concentration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa44c5d4-f928-4abd-95aa-ec154b26d6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].net_concentration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc3c682-9952-427e-9976-48efb6e62c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving PointConcObject calculates new quantities(f.e. c*star) to files\n",
    "#At the moment path hardcoded to windwos, but still ok\n",
    "#default\n",
    "os = \"Windows\"\n",
    "\n",
    "if os==\"Windows\":\n",
    "    folder = 'Point_Data\\\\' + name[:name.find('.')] + '\\\\'\n",
    "elif os==\"Linux\":\n",
    "     folder = 'Files/' + 'Point_Data/' + name[:name.find('.')] + '/'\n",
    "\n",
    "for name in namelist:\n",
    "    for file in files:\n",
    "        \n",
    "        wt.check_directory(output_path + folder)\n",
    "        dict_conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].__check_sum = 8\n",
    "        #dict_conc_ts[name][file].__check_sum = 8\n",
    "       \n",
    "        if full_scale == 'ms':\n",
    "            dict_conc_ts[name][file].save2file_ms(file, out_dir=output_path + folder)\n",
    "        elif full_scale == 'fs':\n",
    "            dict_conc_ts[name][file].save2file_fs(file, out_dir=output_path + folder)\n",
    "        elif full_scale == 'nd':\n",
    "            dict_conc_ts[name][file].save2file_nd(file, out_dir=output_path + folder)\n",
    "        else:\n",
    "            print(\n",
    "                \"Error: invalid input for full_scale. Data can only be computed in model scale (full_scale='ms'), full scale (full_scale='fs'), or non-dimensionally (full_scale=nd).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ce01f0-6540-43a2-801c-7735e72b84a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving averages and stats to files under folder Point_Data_avg/Point_Data_stats\n",
    "#At the moment path hardcoded to windows, but still ok\n",
    "os = \"Windows\"\n",
    "if os==\"Windows\":\n",
    "    folder_avg = 'Point_Data_avg\\\\' + name[:name.find('.')] + '\\\\'\n",
    "    folder_stats = 'Point_Data_stats\\\\' + name[:name.find('.')] + '\\\\'\n",
    "elif os==\"Linux\":\n",
    "    folder_avg = 'Files/' + 'Point_Data_avg/' + name[:name.find('.')] + '/'\n",
    "    folder_stats = 'Files/' + 'Point_Data_stats/' + name[:name.find('.')] + '/'\n",
    "\n",
    "#Stats Full ausgabe: Mean, percentile 95, percentile 5, peak2Mean \n",
    "for name in namelist:\n",
    "    for file in files: \n",
    "        wt.check_directory(output_path + folder_avg)\n",
    "        wt.check_directory(output_path + folder_stats)\n",
    "        dict_conc_ts[name][file].save2file_avg(file, out_dir=output_path + folder_avg)\n",
    "        dict_conc_ts[name][file].save2file_fullStats(file, out_dir=output_path + folder_stats)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a8f1f-952f-424a-b534-38ec2dd2580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conc_ts[name][file].calc_percentiles(percentiles=[10, 90, 95], var='net_concentration'))\n",
    "print(np.mean(conc_ts[name][file].net_concentration))\n",
    "print(np.std(conc_ts[name][file].net_concentration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bd3343-855d-4e90-bf4c-134b614f4456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concentration fluctuation analysis \n",
    "#Intermittency based on threshold, peak2Mean, concentration variance spectral density distribution\n",
    "\n",
    "#Seettings intermittency calculation\n",
    "threshold_type=\"ratio\" #ratio, absolute\n",
    "threshold_method=\"mean\" #mean, std\n",
    "intermittency_threshold=1.5 #-> if type=ratio,method mean, threshold=threshold*mean(concentration), if type=absolute: threshold=threshold\n",
    "\n",
    "conc_ts[name][file].analyze_concentration_fluctuations(dimensionless=\"False\",\n",
    "                                                       intermittency_threshold=intermittency_threshold,threshold_method=threshold_method)\n",
    "#power(variance) of concentration changes for different frequencies/timer interval lengths \n",
    "#Low-frequency peak: Slow, gradual concentration changes\n",
    "#High-frequency peak: Rapid, quick concentration fluctuations\n",
    "#Broad spectrum: Mixed or complex concentration dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7768a7ed-d1d0-49b0-8aa1-f57849e3b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing incorporation of STJF for intermittency (Sequential time join fourier, leaves time domain intact)\n",
    "#STFTs calculates sequential FFTs and can be used as a way of quantifying the change of a spectrum over time.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import stft\n",
    "\n",
    "#0.005 6.0045 2.276105 12.835903 2.381506 3.91625 \n",
    "#0.015 5.992015 1.911356 28.29813 2.390326 3.914681 \n",
    "sampling_rate = 100#Hz\n",
    "\n",
    "f, t, Zxx = stft(conc_ts[name][file].wtref, fs=sampling_rate, nperseg=256, noverlap=128)\n",
    "\n",
    "plt.pcolormesh(t, f, np.abs(Zxx), shading='gouraud')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [s]')\n",
    "#plt.yscale('log')  #logarithmic scale?\n",
    "plt.ylim(0,1)\n",
    "#plt.colorbar(label='Magnitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a21835-eb42-494d-86c0-f5022351003a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For completeness also calculate further characteristic metrics of flow/ wind velocity time series (from wtref ts), skewness ..\n",
    "#print(conc_ts[name][file].calculate_turbulence_intensity(dimensionless=\"True\",returnDistribution=\"False\",returnMetrics=\"True\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e72a408-8094-48c9-ba67-2432ead8e517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from windtunnel.concentration.CompareDatasets import compare_point_concentrations_3\n",
    "#Give overview/comparison for the data, one plot including of of the plots choosen in the list \"functionsForOverview\n",
    "#Means, Pdf, Cdf, PowerDensity: Number of ts does not matter that much\n",
    "#Scatterplot: use only 2 ts\n",
    "#Histogram, Boxplot: would also recommend not to many, because of overlapping of the histograms for comparison, space for the boxplots..\n",
    "\n",
    "#functionsForOverview = [\"all\"] #defaul -> all of the available plots\n",
    "#all_plot_types = [\n",
    "#        \"Histogram\", \"Pdf\", \"Cdf\", \"Means\", \"BoxPlot\", \n",
    "#        \"QuantilPlot\", \"ScatterPlot\", \"ResidualPlot\", \"Autocorrelation\"\n",
    "#    ]\n",
    "    \n",
    "functionsForOverview = [\n",
    "    \"Histogram\",\n",
    "    \"BoxPlot\"\n",
    "    #\"\",\n",
    "    \"Pdf\",\n",
    "    \"Cdf\",\n",
    "    \"Means\",\n",
    "    \"PowerDensity\"\n",
    "        ]\n",
    "\n",
    "#Choose which concentration time series/PointObjekts to show in the overview/comparison plot\n",
    "DataPointsConc = [\n",
    "    conc_ts[namelist[0]][files[0]],#\n",
    "    conc_ts[namelist[0]][files[1]]\n",
    "]\n",
    "\n",
    "compare_point_concentrations_3(DataPointsConc,functionsForOverview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a30d448-4fe1-4ffb-864a-5212b409ca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start visualisation single plots, adjustable\n",
    "#ReadIn/Choose data (PointObjects) from the analysis above, to use for the separat plot visualisations, import plotting functions\n",
    "\n",
    "#Specify files\n",
    "#DataPointsConc = [\n",
    "#    conc_ts[namelist[0]][files[0]],\n",
    "#    conc_ts[namelist[0]][files[1]]\n",
    "#]\n",
    "#All files read-in\n",
    "DataPointsConc=[]\n",
    "for i in range(0,len(files)):\n",
    "    DataPointsConc.append(\n",
    "        conc_ts[namelist[0]][files[i]]\n",
    "    )\n",
    "#Labels    \n",
    "labels = [f\"Dataset {i}\" for i in range(1,len(DataPointsConc)+1)]\n",
    "\n",
    "print(labels)\n",
    "print(DataPointsConc)\n",
    "\n",
    "#Load all functions for plotting\n",
    "from windtunnel.concentration.CompareDatasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1367507-7283-4df1-a0f6-568a59e9f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xLabel=\"Datasets\"\n",
    "yLabel=\"Mean concentration[ppmV]\" \n",
    "dimensionless=\"False\"\n",
    "xAchse = None \n",
    "yAchse=(72,79) #None \n",
    "error_values=0.2 #[0.5,0.2,0.1] #For error values overgive one number which is cast to all values, or an array if specify different errors for each measurements\n",
    "errorType=\"absolute\"\n",
    "test = create_means(DataPointsConc,error_values,dimensionless=dimensionless,labels=None,xLabel=xLabel,yLabel=yLabel,xAchse=xAchse,yAchse=yAchse)\n",
    "#plt.savefig(\"Mean_comparison.png\",test) #To save image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bbd2cf-a5a1-4070-8df4-8fb2e867674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xLabel=\"Concentration[-]\"\n",
    "yLabel=\"Density\"\n",
    "dimensionless=\"True\"\n",
    "create_pdf(DataPointsConc,dimensionless=\"True\",labels=None,xLabel=xLabel,yLabel=yLabel,xAchse=None,yAchse=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61cfae6-7b6b-427d-a273-0524d5ae04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xLabel=\"Datasets\"\n",
    "yLabel=\"Concentration[ppmV]\"\n",
    "xLabel=\"Datasets\"\n",
    "yLabel=\"Concentration[ppmV]\"\n",
    "create_histogram(DataPointsConc,dimensionless=\"False\",labels=None,xLabel=xLabel,yLabel=yLabel,xAchse=None,yAchse=None)\n",
    "\n",
    "\"\"\"\n",
    "#import scipy.stats as stats\n",
    "#import seaborn as sns\n",
    "sns.histplot(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].net_concentration, kde=True)\n",
    "sns.displot(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].net_concentration,kind=\"kde\")\n",
    "#mu = np.mean(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].net_concentration)\n",
    "#sigma = np.sqrt(np.var(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].net_concentration))\n",
    "#value = np.random.normal(loc=mu,scale=sigma,size=len(conc_ts[next(iter(conc_ts))][next(iter(conc_ts[next(iter(conc_ts))]))].net_concentration))\n",
    "#sns.distplot(value)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeae394-f4f9-4443-b6d1-70ef67ea9e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "yLabel=None\n",
    "xLabel=\"Concentration[-]\"\n",
    "dimensionless=\"True\"\n",
    "create_cdf(DataPointsConc,dimensionless=dimensionless,labels=None,xLabel=xLabel,yLabel=yLabel,xAchse=None,yAchse=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab141bc0-c6f7-4941-a325-e735a5561c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = powerDensityPlot(DataPointsConc,dimensionless=\"False\",plot=True,labels=None,xLabel=None,yLabel=None,xAchse=None,yAchse=None)\n",
    "plt.savefig(\"test.png\",test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e19688-45df-46b2-af11-cee45447748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of how to load/Read-in averages from file to use f.e. in map or for plotting\n",
    "from windtunnel.concentration.utils import load_avg_file\n",
    "\n",
    "file_path = \"/home/sabrina/Desktop/Schreibtisch/Arbeit_2025/windtunnel_software/Data/\"\n",
    "file_name = \"Point_Data_avg\\BFS_BD3_MP01_000_01\\_avg_BFS_BD3_MP01_000_01.ts#0\" #Location of saved file\n",
    "data_dict = load_avg_file(file_path + file_name)\n",
    "\n",
    "\n",
    "print(data_dict.keys())\n",
    "print(data_dict['metadata'].keys())\n",
    "print(data_dict['metadata']['x (measurement relativ to source)']['value'])\n",
    "print(data_dict['metadata']['y (measurement relativ to source)']['value'])\n",
    "print(data_dict['metadata']['z (measurement relativ to source)']['value'])\n",
    "\n",
    "x = data_dict['metadata']['x (measurement relativ to source)']['value']\n",
    "y = data_dict['metadata']['y (measurement relativ to source)']['value']\n",
    "z = data_dict['metadata']['z (measurement relativ to source)']['value']\n",
    "c = data_dict['data'][0]['net_concentration [ppmV]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0bebbf-957e-4a69-8cfc-887b0a8157fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy_stl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3243f169-6101-4ad8-a70c-860b3a8089af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start visualisation of map with concentration location and averages, with model in background\n",
    "from windtunnel.concentration.utils import stl_to_2d_plot, add_crosses, show_multiple_projections\n",
    "from windtunnel.concentration.utils import plot_stl_3d, add_crosses_3d\n",
    "from windtunnel.concentration.utils import add_velocity_field\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b350996-a0af-475b-9b74-e78654514c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your STL file\n",
    "stl_file = \"/home/sabrina/Schreibtisch/Arbeit_2025/FreeCAD/20240206_BfS_model_scale_complete.stl\"\n",
    "    \n",
    "# Define XY coordinates of concentration measurements\n",
    "\n",
    "#model scale\n",
    "\"\"\"\n",
    "points = [\n",
    "   #(-1020,0),\n",
    "   (-970,-105),\n",
    "   (930,270),\n",
    "   (-850,0),\n",
    "    (15, 25),\n",
    "    (20, 10),\n",
    "    (25, 15),\n",
    "    (30, 30),\n",
    "    #(x,y)\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "#Read-in from avg files\n",
    "from windtunnel.concentration.utils import load_avg_file\n",
    "file_path = \"/home/sabrina/Desktop/Schreibtisch/Arbeit_2025/windtunnel_software/Data/\"\n",
    "file_names = [\n",
    "    \"Point_Data_avg\\BFS_BD3_MP01_000_01\\_avg_BFS_BD3_MP01_000_01.ts#0\",\n",
    "    \"Point_Data_avg\\BFS_BD3_MP01_000_01\\_avg_BFS_BD3_MP01_000_01.ts#0\"\n",
    "]\n",
    "points_ms,values_ms, wind_speeds = [],[],[]\n",
    "for file_name in file_names:\n",
    "    data_dict = load_avg_file(file_path + file_name)\n",
    "    x = data_dict['metadata']['x (measurement relativ to source)']['value']\n",
    "    y = data_dict['metadata']['y (measurement relativ to source)']['value']\n",
    "    #z.append(data_dict['metadata']['z (measurement relativ to source)']['value'])\n",
    "    c = data_dict['data'][0]['net_concentration [ppmV]']\n",
    "    #To test out wind speeds\n",
    "    wind_speeds.append(data_dict['metadata']['wtref']['value'])\n",
    "    points_ms.append((x,y))\n",
    "    values_ms.append(c)\n",
    "    \n",
    "ref_position = (0,0)\n",
    "\n",
    "\n",
    "#####Add velocity field\n",
    "#Velocity time series values for background overlaying wind field\n",
    "wind_speeds = [\n",
    "    0,\n",
    "    1,\n",
    "    2,\n",
    "    3\n",
    "]\n",
    "interpolate_windField = True #Interpolate between wind field measurement locations\n",
    "\n",
    "#Corresponding locations of measured velocites\n",
    "points_wtref = [\n",
    "    (-1800,-1800),\n",
    "    (1800,-1800),\n",
    "    (-1800,1800),\n",
    "    (1800,1800)\n",
    "]\n",
    "\n",
    "\n",
    "#Average concentration values\n",
    "values = [9.2484,3.557,72.931, 15, 25, 35, 45]#,c] #[77.262008,\n",
    "# Define thresholds and corresponding colors\n",
    "thresholds = [10, 20, 30, 40]\n",
    "colors = ['blue','green', 'yellow', 'orange', 'red']\n",
    "\n",
    "#Call stl to polygon print\n",
    "fig, ax = stl_to_2d_plot(stl_file, projection='xy',toFullScale=\"False\",scaling=1)\n",
    "#fig, ax = plot_stl_3d(stl_file, azim=0,elev=30,x_range=[-1000,1000],y_range=[-200,200], z_range=[-200,200])\n",
    "# Add velocity field (speeds only)\n",
    "add_velocity_field(ax, points_wtref, values=wind_speeds, interpolate=interpolate-windField, grid_density=40, transparencyFactor=0.2,is_latlon=False,toFullScale=False, zorder=5,show_contour_lines=False)\n",
    "# Add crosses to the plot#\n",
    "add_crosses(ax, points_ms, values=values_ms, thresholds=thresholds, colors=colors,size=80, linewidth=1.5)\n",
    "#add_crosses_3d(ax, points, values=values, thresholds=thresholds, colors=colors,size=80, linewidth=1.5)\n",
    "# Show the plot\n",
    "ax.set_xlabel(\"X_ms[mm]\")\n",
    "ax.set_ylabel(\"Y_ms[mm]\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"stl_with_crosses.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ed071-cecc-4f68-9a15-53305ba1075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from windtunnel.concentration.utils import plot_stl_3d, add_crosses_3d, load_data_from_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Path to your STL file for city structure\n",
    "stl_file = \"/home/sabrina/Schreibtisch/Arbeit_2025/FreeCAD/20240711 UBA1c_2.stl\"\n",
    "#Path to csv file containing locations and concentration values measured in format /x,y,z,c\n",
    "path_file = \"/home/sabrina/Schreibtisch/Arbeit_2025/FreeCAD/UBA/loc+value.csv\"\n",
    "points, values = load_data_from_csv(path_file) #File is in full scale \n",
    "\n",
    "# Define 3D points for crosses (x, y, z coordinates)\n",
    "\"\"\"\n",
    "points = [\n",
    "    (-970, -105, 50),\n",
    "    (930, 270, 10),\n",
    "    (-850, 0, 20),\n",
    "    (15, 25, 30),\n",
    "    (20, 10, 15),\n",
    "    (25, 15, 40),\n",
    "    (30, 30, 60)\n",
    "]\n",
    "# Values for color-coding the crosses\n",
    "values = [9.2484, 3.557, 72.931, 15, 25, 35, 45]\n",
    "\"\"\"\n",
    "\n",
    "#For full scale trafo\n",
    "scale = 400\n",
    "\n",
    "x_range=None#[-30000,30000]#[-20000,-10000]#[-30000,30000]#[-10000,0]#[-30000,30000]\n",
    "y_range=None#[-45000,45000]#[5000,15000]#[-45000,45000]\n",
    "#x_range=[-30000,-10000]#[-30000,30000]#[-20000,-10000]#[-30000,30000]#[-10000,0]#[-30000,30000]\n",
    "#y_range=[30000,50000]#[-45000,45000]#[5000,15000]#[-45000,45000]\n",
    "z_range=[-15000,20000]\n",
    "#To Full scale range\n",
    "#x_range = [i * scale / 1000  for i in x_range] \n",
    "#y_range = [i * scale / 1000  for i in y_range] \n",
    "#z_range = [i * scale / 1000  for i in z_range]\n",
    "fig, ax = plot_stl_3d(stl_file,elev=30,azim=320,x_range=x_range,y_range=y_range,z_range=z_range,toFullScale=\"True\",scaling=scale)\n",
    "#fig, ax = plot_stl_3d(stl_file,elev=0,azim=0)\n",
    "# Define thresholds and corresponding colors\n",
    "thresholds = [10, 20, 30, 40] \n",
    "thresholds = [i / 10000 for i in thresholds]\n",
    "colors = ['blue', 'green', 'yellow', 'orange', 'red']\n",
    "\n",
    "add_crosses_3d(ax, points, values=values, thresholds=thresholds, colors=colors,\n",
    "              size=80, linewidth=1.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"stl_with_crosses.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e006ac-2639-4450-9649-e1e542d53baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abea08db-e88a-4e22-80f2-a47d04eeb21e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
